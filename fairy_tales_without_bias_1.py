# -*- coding: utf-8 -*-
"""Fairy Tales without bias 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A_2A_7jTKm1g4o8QAULGmTS7DtIKYVbx
"""

import requests
import re
import spacy
from textblob import TextBlob

nlp = spacy.load("en_core_web_sm")

def clean_text(text: str) -> str:
    """Remove extra spaces and newlines"""
    return re.sub(r'\s+', ' ', text)

def identify_characters(doc):
    """Identify named characters using NER"""
    chars = {}
    for ent in doc.ents:
        if ent.label_ == "PERSON":
            name = ent.text.strip()
            chars[name] = chars.get(name, 0) + 1
    return chars

def assign_roles_enhanced(doc, characters):
    """Assign multiple roles per character"""
    roles = {name: set() for name in characters.keys()}
    role_keywords = {
        "royalty": ["king", "queen", "prince", "princess", "duke", "duchess", "emperor", "empress"],
        "servant": ["servant", "maid", "butler", "attendant", "handmaid", "slave"],
        "hero": ["hero", "heroine", "brave", "knight", "savior", "rescued", "warrior", "champion"],
        "villain": ["villain", "witch", "ogre", "monster", "evil", "sorcerer", "dark lord"],
        "mentor": ["wizard", "teacher", "guide", "counselor"],
        "family": ["mother", "father", "sister", "brother", "child"]
    }

    for token in doc:
        name = token.text
        if name in characters:
            start = max(token.i - 7, 0)
            end = min(token.i + 7, len(doc))
            window = doc[start:end]
            for word in window:
                word_lower = word.text.lower()
                for role, keywords in role_keywords.items():
                    if any(k in word_lower for k in keywords):
                        roles[name].add(role)

    return {k: list(v) for k, v in roles.items()}

def detect_gender_mentions(doc):
    """Detect gendered terms and pronouns"""
    gender_mentions = {"male": 0, "female": 0}
    pronoun_usage = {"he": 0, "she": 0, "they": 0}

    male_terms = ["he", "him", "boy", "man", "king", "prince"]
    female_terms = ["she", "her", "girl", "woman", "queen", "princess"]

    for token in doc:
        word = token.text.lower()
        if word in pronoun_usage:
            pronoun_usage[word] += 1
        if word in male_terms:
            gender_mentions["male"] += 1
        elif word in female_terms:
            gender_mentions["female"] += 1

    return gender_mentions, pronoun_usage

def compute_gender_balance_score(gender_mentions):
    total = sum(gender_mentions.values())
    if total == 0:
        return 1.0
    return 1 - abs(gender_mentions["male"] - gender_mentions["female"]) / total

def compute_role_diversity_score_weighted(roles):
    if not roles:
        return 0
    total_roles = sum(len(r) for r in roles.values())
    unique_roles = set(r for role_list in roles.values() for r in role_list)
    diversity = len(unique_roles) / (total_roles + 0.5)
    return min(diversity, 1.0)

def compute_stereotype_penalty_enhanced(doc):
    stereotype_words = ["beautiful", "handsome", "weak", "strong", "brave", "timid"]
    count = sum(1 for token in doc if token.text.lower() in stereotype_words)
    return max(0, 1 - (count / 20)), count

def character_sentiment(doc, characters):
    """Compute average sentiment around each character"""
    sentiment = {}
    for name in characters:
        occurrences = [sent.text for sent in doc.sents if name in sent.text]
        if occurrences:
            avg_sent = sum(TextBlob(sent).sentiment.polarity for sent in occurrences) / len(occurrences)
        else:
            avg_sent = 0
        sentiment[name] = round(avg_sent, 3)
    return sentiment

def analyze_book_from_url(book_url: str, title: str):
    resp = requests.get(book_url, timeout=20)
    text = clean_text(resp.text)[:20000]
    doc = nlp(text)

    chars = identify_characters(doc)
    roles = assign_roles_enhanced(doc, chars)
    gender_mentions, pronoun_usage = detect_gender_mentions(doc)
    gbs = compute_gender_balance_score(gender_mentions)
    rds = compute_role_diversity_score_weighted(roles)
    sp, stereotype_count = compute_stereotype_penalty_enhanced(doc)
    sentiment = character_sentiment(doc, chars)

    # Identify male and female characters based on basic keyword assumptions in names
    male_keywords = ['king', 'prince', 'man', 'he']
    female_keywords = ['queen', 'princess', 'woman', 'she']
    male_chars = [name for name in chars if any(k in name.lower() for k in male_keywords)]
    female_chars = [name for name in chars if any(k in name.lower() for k in female_keywords)]

    result = {
        "title": title,
        "gender_balance_score": round(gbs * 10, 2),
        "role_diversity_score": round(rds * 10, 2),
        "stereotype_penalty": round(sp * 10, 2),
        "gender_mentions": gender_mentions
    }
    return result


url_cinderella = "https://www.gutenberg.org/files/23303/23303-h/23303-h.htm?utm_source=chatgpt.com"
url_beauty_beast = "https://www.gutenberg.org/cache/epub/7074/pg7074-images.html"

def pretty_print_report(result):
        print(f"\nðŸ“– Title: {result['title']}\n")

        print("ðŸ‘¥ Gender Bias:")
        print(f"- Gender Balance Score: {result['gender_balance_score']}")
        print(f"- Gender Mentions: Male = {result['gender_mentions']['male']}, Female = {result['gender_mentions']['female']}")

        if result['gender_mentions']['male'] > result['gender_mentions']['female'] * 1.5:
            print("  â†’ Heavily biased toward male representation.\n")
        elif result['gender_mentions']['female'] > result['gender_mentions']['male'] * 1.5:
            print("  â†’ Heavily biased toward female representation.\n")
        else:
            print("  â†’ Relatively balanced gender representation.\n")


        print("ðŸŽ­ Role Diversity:")
        print(f"- Role Diversity Score: {result['role_diversity_score']}")
        print(f"  â†’ {'Roles are well distributed across characters.' if result['role_diversity_score'] > 7 else 'Characters tend to be boxed into one or two common roles.' if result['role_diversity_score'] >= 4 else 'Highly stereotypical and limited roles.'}\n")

        print("ðŸ§  Stereotype Bias:")
        print(f"- Stereotype Penalty: {result['stereotype_penalty']}")
        print(f"  â†’ {'Minimal use of stereotypes.' if result['stereotype_penalty'] > 7 else 'Some stereotypical language is used, but not excessively.' if result['stereotype_penalty'] >= 4 else 'Frequent stereotypical or biased language detected.'}")
        print("-" * 50)


if __name__ == "__main__":
        # When run directly, perform example analysis. Importing this module won't trigger heavy work.
        results = [
                analyze_book_from_url(url_cinderella, "Cinderella"),
                analyze_book_from_url(url_beauty_beast, "Beauty & the Beast")
        ]

        for result in results:
                pretty_print_report(result)

def pretty_print_report(result):
    print(f"\nðŸ“– Title: {result['title']}\n")

    print("ðŸ‘¥ Gender Bias:")
    print(f"- Gender Balance Score: {result['gender_balance_score']}")
    print(f"- Gender Mentions: Male = {result['gender_mentions']['male']}, Female = {result['gender_mentions']['female']}")

    if result['gender_mentions']['male'] > result['gender_mentions']['female'] * 1.5:
      print("  â†’ Heavily biased toward male representation.\n")
    elif result['gender_mentions']['female'] > result['gender_mentions']['male'] * 1.5:
      print("  â†’ Heavily biased toward female representation.\n")
    else:
      print("  â†’ Relatively balanced gender representation.\n")


    print("ðŸŽ­ Role Diversity:")
    print(f"- Role Diversity Score: {result['role_diversity_score']}")
    print(f"  â†’ {'Roles are well distributed across characters.' if result['role_diversity_score'] > 7 else 'Characters tend to be boxed into one or two common roles.' if result['role_diversity_score'] >= 4 else 'Highly stereotypical and limited roles.'}\n")

    print("ðŸ§  Stereotype Bias:")
    print(f"- Stereotype Penalty: {result['stereotype_penalty']}")
    print(f"  â†’ {'Minimal use of stereotypes.' if result['stereotype_penalty'] > 7 else 'Some stereotypical language is used, but not excessively.' if result['stereotype_penalty'] >= 4 else 'Frequent stereotypical or biased language detected.'}")
    print("-" * 50)

# # Print the result
# for result in results:
#     pretty_print_report(result)

# # https://www.gutenberg.org/cache/epub/76970/pg76970-images.html
# # https://www.gutenberg.org/cache/epub/76967/pg76967-images.html
# # https://www.gutenberg.org/cache/epub/1342/pg1342-images.html

# import pandas as pd

# data = [
#     {"Book": "Cinderella", "Gender Balance": 1.95, "Role Diversity": 8.0, "Stereotype Penalty": 7.5},
#     {"Book": "Beauty and the Beast", "Gender Balance": 8.59, "Role Diversity": 6.67, "Stereotype Penalty": 8.0}
# ]

# df = pd.DataFrame(data)
# df

# import matplotlib.pyplot as plt

# titles = ['Cinderella', 'Beauty & the Beast']
# gender_balance_scores = [1.95, 8.59]
# role_diversity_scores = [8.00, 6.67]
# stereotype_penalties = [7.5, 8.0]

# # Plotting data
# x = range(len(titles))
# width = 0.25

# plt.bar([p - width for p in x], gender_balance_scores, width, label='Gender Balance')
# plt.bar(x, role_diversity_scores, width, label='Role Diversity')
# plt.bar([p + width for p in x], stereotype_penalties, width, label='Stereotype Penalty')

# plt.xlabel('Stories')

# plt.title('Bias Scores Comparison: Cinderella vs Beauty & the Beast')
# plt.xticks(x, titles)
# plt.legend()
# plt.show()